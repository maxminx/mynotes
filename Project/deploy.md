[[deepLearning]]

## 影响推理速度infer speed的因素

1：计算速度和计算量OPs，浮点计算量表示为FLOPs(floating point operations)。矩阵相加的计算量级约w*h；卷积计量级约元素乘法的数量，忽略加法的数量。

2：访存速度和访存量，对推理时间起很大影响。对于 Eltwise Sum 来讲，两个大小均为 (N, C, H, W) 的 Tensor 相加，访存量是 (2 + 1) x N x C x H x W x sizeof(data_type)，其中 2 代表读两个 Tensor，1 代表写一个 Tensor；对于卷积就是输入层的量+输入卷积核的量+输出结果的量。访存量起着重大影响，需要注意模型设计。

3：参数量，决定占用内存和磁盘的空间大小

4：内存占用

5：计算密度，又叫计算访存比=(计算量OPs/访存量Bites)

6：计算速度=min(计算密度×带宽， cpu等计算设备峰值计算速度)

7：计算时间=计算量/计算速度。对于访存密集型算子，推理时间跟访存量呈线性关系，而对于计算密集型算子，推理时间跟计算量呈线性关系。

8：计算密集型算子conv，FC，Deconv等；IO密集型算法Relu，eltwise add，concat等。对于conv算子，增加group或减少channel数量都会减少计算密度。在很多设备上，depthwise conv都是访存密集型算子

9：RoofLine模型，横轴为计算密度，纵轴为计算速度。硬件理论性能-硬件损耗-系统OS损耗-软件实现损耗==真实的性能

**建议**

1：尽量使用常用的算子参数，例如 Conv 尽量使用 3x3_s1/s2，1x1*_*s1/s2 等，这些常用参数往往会被特殊优化，性能更好。

2：了解目标硬件的峰值算力和内存带宽，最好是实测值

3：尽量采用经典结构，大部分框架会对这类结构进行图优化，能够有效减少计算量与访存量。例如 Conv->BN->ReLU 就会融合成一个算子，但 Conv->ReLU->BN 就无法直接融合 BN 层

4：CNN 网络 channel 数尽量选择 4/8/16/32 的幂次

5：一些研究工作，例如 ShuffleNetV2， 已经在设计网络的时候兼顾访存量了。但据我所知目前还没有像 DepthWise Conv 一样经典的节省访存量的模型结构。

6：低精度/量化有的时候节省访存量的意义远大于节省计算量

7：一些非常细碎乃至毫无意义的后处理算子，例如 Gather、Squeeze、Unsqueeze 等，最好给融合掉。这种现象往往见于 PyTorch 导出 onnx 的时候，可以尝试使用 onnxsim 等工具来进行融合

8：尝试一些部署无感的技巧，例如蒸馏、RepVGG

参考：
https://zhuanlan.zhihu.com/p/411522457

## 减枝

训练后对某些卷积核norm小于阈值，则删除，再tune训练